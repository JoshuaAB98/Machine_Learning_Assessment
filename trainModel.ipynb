{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253 entries, 0 to 252\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       253 non-null    float64\n",
      " 1   Open       253 non-null    float64\n",
      " 2   High       253 non-null    float64\n",
      " 3   Low        253 non-null    float64\n",
      " 4   Close      253 non-null    float64\n",
      " 5   Adj Close  253 non-null    float64\n",
      " 6   Volume     253 non-null    float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 14.0 KB\n",
      "\n",
      " None\n",
      "\n",
      "________________________________________________________________\n",
      "              Date        Open        High         Low       Close   Adj Close  \\\n",
      "0    1.576714e+09   79.463997   81.370003   79.300003   80.807999   80.807999   \n",
      "1    1.576800e+09   82.057999   82.599998   80.038002   81.117996   81.117996   \n",
      "2    1.577059e+09   82.356003   84.402000   82.000000   83.844002   83.844002   \n",
      "3    1.577146e+09   83.671997   85.094002   82.538002   85.050003   85.050003   \n",
      "4    1.577318e+09   85.582001   86.695999   85.269997   86.188004   86.188004   \n",
      "..            ...         ...         ...         ...         ...         ...   \n",
      "248  1.607904e+09  619.000000  642.750000  610.200012  639.830017  639.830017   \n",
      "249  1.607990e+09  643.280029  646.900024  623.799988  633.250000  633.250000   \n",
      "250  1.608077e+09  628.229980  632.500000  605.000000  622.770020  622.770020   \n",
      "251  1.608163e+09  628.190002  658.820007  619.500000  655.900024  655.900024   \n",
      "252  1.608250e+09  668.900024  695.000000  628.539978  695.000000  695.000000   \n",
      "\n",
      "          Volume  \n",
      "0     90535500.0  \n",
      "1     73763500.0  \n",
      "2     66598000.0  \n",
      "3     40273500.0  \n",
      "4     53169500.0  \n",
      "..           ...  \n",
      "248   52040600.0  \n",
      "249   45223600.0  \n",
      "250   42095800.0  \n",
      "251   56270100.0  \n",
      "252  218741900.0  \n",
      "\n",
      "[253 rows x 7 columns] \n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "________________________________________________________________\n",
      " [ 81.370003  82.599998  84.402     85.094002  86.695999  87.061996\n",
      "  85.800003  84.258003  86.139999  90.800003  90.311996  94.325996\n",
      "  99.697998  99.760002  96.987999 105.125999 109.482002 107.568001\n",
      " 102.891998 103.134003 109.716003 118.900002 116.400002 114.772003\n",
      " 112.888    115.362    117.959999 130.175995 130.600006 157.227997\n",
      " 193.798004 169.195999 159.166    153.949997 163.998001 156.701996\n",
      " 157.949997 163.600006 162.593994 172.       188.955994 182.399994\n",
      " 182.612    172.699997 171.320007 162.662003 147.953995 138.104004\n",
      " 148.738007 161.395996 153.304001 149.149994 141.399994 132.600006\n",
      " 133.600006 130.716003 118.900002 121.514     98.973999  94.370003\n",
      "  80.972     90.400002  95.400002  88.400002 102.737999 111.400002\n",
      " 112.       105.160004 103.330002 108.592003 102.790001  98.851997\n",
      " 103.098    104.199997 113.       111.442001 115.036003 130.399994\n",
      " 148.376007 150.626007 151.889999 154.990005 153.113998 150.666\n",
      " 146.800003 146.800003 146.145996 159.897995 161.       160.639999\n",
      " 173.964005 154.554001 152.399994 159.783997 157.960007 159.279999\n",
      " 164.800003 164.800003 168.658005 165.199997 160.671997 161.009995\n",
      " 166.944    164.414001 165.199997 166.5      166.356003 166.919998\n",
      " 165.542007 164.949997 167.       179.800003 181.731995 179.587997\n",
      " 179.149994 177.304001 190.       190.888    205.496002 203.792007\n",
      " 197.595993 199.768005 202.576004 201.       203.839996 203.194\n",
      " 201.776001 202.399994 200.175995 197.195999 199.       202.\n",
      " 217.537994 227.065994 245.600006 275.558014 285.899994 283.451996\n",
      " 281.712006 309.783997 358.997986 318.       310.       306.34201\n",
      " 307.502014 330.       335.       325.283997 337.799988 293.\n",
      " 309.588013 312.940002 306.962006 302.64801  303.410004 301.962006\n",
      " 305.481995 299.967987 303.462006 299.950012 291.5      284.\n",
      " 317.       330.235992 333.76001  369.171997 384.779999 382.200012\n",
      " 404.39801  419.097992 425.799988 405.589996 433.200012 459.119995\n",
      " 463.697998 500.140015 502.48999  479.040009 431.799988 428.\n",
      " 368.73999  369.       398.98999  382.5      420.       461.940002\n",
      " 457.790009 437.790009 451.       455.679993 437.76001  412.149994\n",
      " 399.5      408.730011 428.079987 428.5      433.929993 448.880005\n",
      " 439.130005 433.640015 428.779999 429.899994 439.       434.589996\n",
      " 448.73999  448.890015 465.899994 456.570007 455.950012 447.\n",
      " 431.75     432.950012 445.230011 422.890015 425.76001  430.5\n",
      " 418.600006 418.059998 407.589996 406.980011 427.769989 435.399994\n",
      " 440.       436.570007 452.5      420.089996 418.700012 423.\n",
      " 412.529999 412.450012 462.       496.       508.609985 502.5\n",
      " 526.       559.98999  574.       598.780029 607.799988 597.849976\n",
      " 571.539978 598.969971 599.039978 648.789978 651.280029 654.320007\n",
      " 627.75     624.       642.75     646.900024 632.5      658.820007\n",
      " 695.      ] \n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "The total of training dataset (177, 7)\n",
      "\n",
      "The total of test dataset (76, 7)\n",
      "Mean absolute error: 3.50\n",
      "Mean squared error: 45.62\n",
      "Root mean squared error: 6.75\n",
      "R2 score:  0.9985053566149974\n",
      "R2_Train score:  0.9998192306902726\n",
      "\n",
      "This is the prediction [82.50383944] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "from io import StringIO\n",
    "import csvfile as csvfile\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Declare header names\n",
    "stock_headers = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "\n",
    "# Read the data from the csv file\n",
    "stock_data = read_csv(\"csvs/TSLA.csv\", names=stock_headers)\n",
    "\n",
    "# print(stock_data)\n",
    "\n",
    "stock_data['Volume'] = pd.to_numeric(stock_data['Volume'].astype(float))\n",
    "\n",
    "# check_missing_data = stock_data[stock_data.isna().any(axis=1)]\n",
    "# print('\\nThese are instances with missing data \\n', check_missing_data) #print instances with missing data\n",
    "\n",
    "print(\"\\n\",stock_data.info())\n",
    "\n",
    "stock_data = pd.DataFrame(data=stock_data, columns=stock_headers)\n",
    "\n",
    "train_headers = ['Date', 'Open', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "target_header = ['High']\n",
    "\n",
    "X = stock_data[train_headers]\n",
    "y = stock_data[target_header]\n",
    "\n",
    "# stock_data = stock_data.drop(['High', 'Volume'], axis=1)\n",
    "\n",
    "#Get the variable which allows us to carry out multiple linear regression\n",
    "X = stock_data.iloc[:, 0:8]\n",
    "\n",
    "print(\"\\n________________________________________________________________\\n\",X,\"\\n_________________________________________________________________\\n\")\n",
    "\n",
    "#Get the high\n",
    "y = stock_data.iloc[:, 2].values\n",
    "\n",
    "print(\"\\n________________________________________________________________\\n\",y,\"\\n_________________________________________________________________\\n\")\n",
    "\n",
    "\n",
    "#split data into 70:30 train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#print the dimensions of the train test data set\n",
    "print(\"\\nThe total of training dataset\", X_train.shape)\n",
    "print(\"\\nThe total of test dataset\", X_test.shape)\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "#Initialise linear regression model\n",
    "dt_model = DecisionTreeRegressor(random_state=SEED)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=25, random_state=2)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "#predict model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "#predict model on train data\n",
    "y_pred_train = rf_model.predict(X_train)\n",
    "\n",
    "#Evaluate evaluation\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "#Visualise feature importance\n",
    "importances = pd.Series(data=rf_model.feature_importances_, index=X_train.columns)\n",
    "\n",
    "#Sort based on value\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "#Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='blue')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()\n",
    "\n",
    "#Printing the model evaluation values\n",
    "print('Mean absolute error: {:.2f}'.format(mae))\n",
    "print('Mean squared error: {:.2f}'.format(mse))\n",
    "print('Root mean squared error: {:.2f}'.format(rmse))\n",
    "print('R2 score: ', r2)\n",
    "print('R2_Train score: ', r2_train)\n",
    "\n",
    "pred_my_value = rf_model.predict([[1577923200.0,46.860001,49.250000,46.630001,49.099998,49.099998,80331100]]) #49.250000 expected High\n",
    "print(\"\\nThis is the prediction\", pred_my_value, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}